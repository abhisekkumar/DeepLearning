{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdash/.local/lib/python2.7/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import dicom # The only library for reading dicom files\n",
    "import os # for doing directory operations \n",
    "import pandas as pd # To load data in the labels data and quickly reference it\n",
    "import pprint\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0015ceb851d7251b8f399e39779d1e7d</th>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0030a160d58723ff36d73f41b170ec21</th>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003f41c78e6acfa92430a057ac0b306e</th>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006b96310a37b36cccb2ab48d10b49a3</th>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008464bb8521d09a42985dd8add3d0d2</th>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  cancer\n",
       "id                                      \n",
       "0015ceb851d7251b8f399e39779d1e7d       1\n",
       "0030a160d58723ff36d73f41b170ec21       0\n",
       "003f41c78e6acfa92430a057ac0b306e       0\n",
       "006b96310a37b36cccb2ab48d10b49a3       1\n",
       "008464bb8521d09a42985dd8add3d0d2       1\n",
       "\n",
       "[5 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change this to wherever you are storing your data:\n",
    "# IF YOU ARE FOLLOWING O\n",
    "#N KAGGLE, YOU CAN ONLY PLAY WITH THE SAMPLE DATA, WHICH IS MUCH SMALLER\n",
    "\n",
    "data_dir = '/scratch2/sdash/data/stage1'\n",
    "patients = os.listdir(data_dir)\n",
    "patients.sort()\n",
    "#print(patients[0])\n",
    "labels_df = pd.read_csv('/scratch2/sdash/data/stage1_labels.csv', index_col=0)\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2afe1d301a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ75j9I35xwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2afe30605590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using our saved numpy array to load the data\n",
    "much_data = np.load('TensorflowData.npy')\n",
    "print(len(much_data))\n",
    "#print(much_data)\n",
    "plt.imshow(much_data[1][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Largely inspired from MNIST Deep Tutorial in the website https://www.tensorflow.org\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import numpy as np\n",
    "\n",
    "#tf.device('/gpu:0')  #was trying to \n",
    "IMG_SIZE_PX = 64\n",
    "SLICE_COUNT = 32\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 100\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "keep_rate = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window as you slide about\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x):\n",
    "    #                # 5 x 5 x 5 patches, 1 channel, 32 features to compute.\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,5,1,32])),\n",
    "               #       5 x 5 x 5 patches, 32 channels, 64 features to compute.\n",
    "               'W_conv2':tf.Variable(tf.random_normal([5,5,5,32,64])),\n",
    "               #                                  64 features\n",
    "               'W_fc':tf.Variable(tf.random_normal([131072,1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    #                            image X      image Y        image Z\n",
    "    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "\n",
    "\n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, 131072])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "(299, 3)\n",
      "(499, 3)\n",
      "(249, 3)\n",
      "(748, 3)\n",
      "(646, 3)\n",
      "(1394, 3)\n"
     ]
    }
   ],
   "source": [
    "#Loading of our data which were kept as different batch of data.\n",
    "\n",
    "load_data = np.load('TensorflowData.npy')\n",
    "load_data1 = np.load('TensorflowData1.npy')\n",
    "load_data2 = np.load('TensorflowData2.npy')\n",
    "load_data3 = np.load('TensorflowData3.npy')\n",
    "\n",
    "print(load_data.shape)\n",
    "print(load_data1.shape)\n",
    "final_data = np.append(load_data,load_data1,0)\n",
    "print(final_data.shape)\n",
    "print(load_data2.shape)\n",
    "final_data = np.append(final_data,load_data2,0)\n",
    "print(final_data.shape)\n",
    "print(load_data3.shape)\n",
    "final_data = np.append(final_data,load_data3,0)\n",
    "print(final_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Started\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "#much_data = np.load('muchdata-50-50-20.npy')\n",
    "much_data = final_data\n",
    "\n",
    "# If you are working with the basic sample data, use maybe 2 instead of 100 here... you don't have enough data to really do this\n",
    "train_data = much_data[:-200]\n",
    "validation_data = much_data[-200:]\n",
    "\n",
    "\n",
    "def train_neural_network(x):\n",
    "    \n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    \n",
    "    #saver = tf.train.Saver()\n",
    "    hm_epochs = 6\n",
    "    with tf.Session() as sess:\n",
    "        print (\"Session Started\")\n",
    "        #sess.run(tf.initialize_all_variables())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        successful_runs = 0\n",
    "        total_runs = 0\n",
    "        \n",
    "        #saver.restore(sess, \"model.ckpt\")\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for data in train_data:\n",
    "                if(total_runs%100 == 0):\n",
    "                    print(successful_runs) #for test\n",
    "                total_runs += 1\n",
    "                \n",
    "                try:\n",
    "                    X = data[0]\n",
    "                    Y = data[1]\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                    epoch_loss += c\n",
    "                    successful_runs += 1\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "                    pass\n",
    "                    \n",
    "            \n",
    "            print('Epoch', epoch+1, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "            print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n",
    "            saver = tf.train.Saver()\n",
    "            save_path = saver.save(sess, \"MyModel.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "        print('Done. Finishing accuracy:')\n",
    "        print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n",
    "        \n",
    "        print('fitment percent:',successful_runs/total_runs)\n",
    "\n",
    "# Run this locally:\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt\n\t [[Node: save_7/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_7/Const_0, save_7/RestoreV2_2/tensor_names, save_7/RestoreV2_2/shape_and_slices)]]\n\nCaused by op u'save_7/RestoreV2_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-2b858264e619>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1040, in __init__\n    self.build()\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1070, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 675, in build\n    restore_sequentially, reshape)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 402, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 242, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 668, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt\n\t [[Node: save_7/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_7/Const_0, save_7/RestoreV2_2/tensor_names, save_7/RestoreV2_2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2b858264e619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#save_path = saver.save(sess, \"model.ckpt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(\"Model saved in file: %s\" % save_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Restored\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1426\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1428\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt\n\t [[Node: save_7/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_7/Const_0, save_7/RestoreV2_2/tensor_names, save_7/RestoreV2_2/shape_and_slices)]]\n\nCaused by op u'save_7/RestoreV2_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-2b858264e619>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1040, in __init__\n    self.build()\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1070, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 675, in build\n    restore_sequentially, reshape)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 402, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 242, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 668, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sdash/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt\n\t [[Node: save_7/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_7/Const_0, save_7/RestoreV2_2/tensor_names, save_7/RestoreV2_2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "# we tried to save the moodel and restore it to submit it as a direct use but it did not work\n",
    "saver = tf.train.Saver()\n",
    "#save_path = saver.save(sess, \"model.ckpt\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"model.ckpt\")\n",
    "    #print(\"Model saved in file: %s\" % save_path)\n",
    "    print(\"Model Restored\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "    with open(\"stage1_label.csv\", \"r\") as f1, \\\n",
    "     open(\"Stage2.csv\", \"w\", newline='') as resultFile:\n",
    "    wr = csv.writer(resultFile, dialect='excel')\n",
    "    for var in f1:\n",
    "        wr.writerow([var.rstrip('\\n')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (Deep Learning)",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
